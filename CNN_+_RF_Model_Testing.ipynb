{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fljONDxbA3jM",
        "outputId": "da1f317a-8542-442c-c122-0ea4a3a8023e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "#Initialize the kaggle and the dataset\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rylQo60LA-qc"
      },
      "outputs": [],
      "source": [
        "! touch kaggle.json | echo '{\"username\":\"jundifathan\",\"key\":\"d8ce5ff328ebb2f5dab22dc29dbd4546\"}' > kaggle.json\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylg1RJdCBBGS"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d rizwan123456789/potato-disease-leaf-datasetpld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE1PrhvFBDWX"
      },
      "outputs": [],
      "source": [
        "! unzip potato-disease-leaf-datasetpld.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySZHQKJ4B8Tc"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQJwQKQWBIqZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import glob\n",
        "import cv2\n",
        "import pickle, datetime\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import LSTM, Input, TimeDistributed,Convolution2D,Activation\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from keras.models import load_model\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daA1TfzTFpkO"
      },
      "outputs": [],
      "source": [
        "dir_val = \"/content/PLD_3_Classes_256/Validation/*\"\n",
        "dir_tra = \"/content/PLD_3_Classes_256/Training/*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4IMAQIWUC4Ro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "6087eb53-f99e-49a2-82a7-d455b0a17d5c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6b1410f27ce7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_leaves_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_leaves_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_tra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mleaves_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
          ]
        }
      ],
      "source": [
        "#Create Training Model\n",
        "train_leaves_images = []\n",
        "train_leaves_labels = []\n",
        "for directory_path in glob.glob(dir_tra):\n",
        "    leaves_label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (32, 32))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        train_leaves_images.append(img)\n",
        "        train_leaves_labels.append(leaves_label)\n",
        "train_leaves_images = np.array(train_leaves_images)\n",
        "train_leaves_labels = np.array(train_leaves_labels)\n",
        "\n",
        "train_leaves_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiHLhzMyDCG6"
      },
      "outputs": [],
      "source": [
        "label_to_id = {v:i for i,v in enumerate(np.unique(train_leaves_labels))}\n",
        "id_to_label = {v: k for k, v in label_to_id.items()}\n",
        "train_label_ids = np.array([label_to_id[x] for x in train_leaves_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm2RpSL5DDB4"
      },
      "outputs": [],
      "source": [
        "train_leaves_images.shape, train_label_ids.shape, train_leaves_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UswyOEvKEc3Q"
      },
      "outputs": [],
      "source": [
        "# Create Testing Model\n",
        "test_leaves_images = []\n",
        "test_leaves_labels = []\n",
        "for directory_path in glob.glob(dir_val):\n",
        "    leaves_label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "        img = cv2.resize(img, (32, 32))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        test_leaves_images.append(img)\n",
        "        test_leaves_labels.append(leaves_label)\n",
        "test_leaves_images = np.array(test_leaves_images)\n",
        "test_leaves_labels = np.array(test_leaves_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq95fQClEIGX"
      },
      "outputs": [],
      "source": [
        "label_to_ids = {v:i for i,v in enumerate(np.unique(test_leaves_labels))}\n",
        "id_to_labels = {v: k for k, v in label_to_id.items()}\n",
        "test_label_ids = np.array([label_to_ids[x] for x in test_leaves_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_G8FadjEJTh"
      },
      "outputs": [],
      "source": [
        "test_leaves_images.shape, test_label_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6zUjD3LHFd2"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, N_CATEGORY =train_leaves_images,train_leaves_labels,test_leaves_images,test_leaves_labels,len(label_to_id)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, N_CATEGORY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYAV7AX1HJwI"
      },
      "outputs": [],
      "source": [
        "id_to_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou6ZshiNHjtO"
      },
      "outputs": [],
      "source": [
        "#Create the CNN Architecture\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def get_CNN(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjtyWBZvHKiR"
      },
      "outputs": [],
      "source": [
        "CNN = get_CNN((32,32,3),N_CATEGORY)\n",
        "CNN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGZhRHejHNzC"
      },
      "outputs": [],
      "source": [
        "#Normalization of the images and one-hot encoding of the labels\n",
        "CNN.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy'])\n",
        "X_normalized = np.array(x_train / 255.0 - 0.5 )\n",
        "X_normalized_test = np.array(x_test / 255.0 - 0.5 )\n",
        "\n",
        "label_binarizer = LabelBinarizer()\n",
        "y_one_hot = label_binarizer.fit_transform(y_train)\n",
        "y_one_hot_test = label_binarizer.fit_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywEqDl5lBfMh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Training the model and storing the history\n",
        "Model_Train = CNN.fit(X_normalized, y_one_hot, batch_size=32, epochs=10, verbose=1, validation_data=(X_normalized_test, y_one_hot_test))\n",
        "\n",
        "# Retrieving the training and validation loss values\n",
        "train_loss = Model_Train.history['loss']\n",
        "val_loss = Model_Train.history['val_loss']\n",
        "\n",
        "# Retrieving the training and validation accuracy values\n",
        "train_accuracy = Model_Train.history['accuracy']\n",
        "val_accuracy = Model_Train.history['val_accuracy']\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(range(1, len(val_loss) + 1), val_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plotting the training and validation accuracy\n",
        "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, 'bo-', label='Training Accuracy')\n",
        "plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiNLLJXYRrji"
      },
      "outputs": [],
      "source": [
        "#Save the CNN model for the future use(as it takes hours to be trained!)\n",
        "CNN.save('CNNleaf.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHoY05-RRw5G"
      },
      "outputs": [],
      "source": [
        "#Pick the first Fully-Connected layer as the features which will be of dimension (1 x 256)\n",
        "layer_name = 'dense_2'\n",
        "FC_layer_model = Model(inputs=CNN.input,\n",
        "                                 outputs=CNN.get_layer(layer_name).output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3aG7vsRR1b4"
      },
      "outputs": [],
      "source": [
        "#Find the Features for n number of train images and we will get n x 256\n",
        "#This means we will get 256 features for each images.\n",
        "i=0\n",
        "features=np.zeros(shape=(x_train.shape[0],256))\n",
        "for directory_path in glob.glob(dir_tra):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (32,32))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        FC_output = FC_layer_model.predict(img)\n",
        "        features[i]=FC_output\n",
        "        i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfhy8oBOR8Qg"
      },
      "outputs": [],
      "source": [
        "#Save the features of the train images to use it in future.\n",
        "np.save('features', features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__rSoQFoSBxE"
      },
      "outputs": [],
      "source": [
        "#Name the feature rows as f_0, f_1, f_2...\n",
        "feature_col=[]\n",
        "for i in range(256):\n",
        "    feature_col.append(\"f_\"+str(i))\n",
        "    i+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spZ4XOXLSDHF"
      },
      "outputs": [],
      "source": [
        "#Create DataFrame with features and coloumn name\n",
        "train_features=pd.DataFrame(data=features,columns=feature_col)\n",
        "feature_col = np.array(feature_col)\n",
        "\n",
        "train_class = list(np.unique(train_label_ids))\n",
        "print('Training Features Shape:', train_features.shape)\n",
        "print('Training Labels Shape:', train_label_ids.shape)\n",
        "train_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNVuf4kWSEoF"
      },
      "outputs": [],
      "source": [
        "#Feed the extracted features with the labels to RANDOM FOREST\n",
        "rf = RandomForestClassifier(n_estimators = 50, random_state = 40, max_features=5)\n",
        "\n",
        "rf.fit(train_features, train_label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqi1gAttSGFq"
      },
      "outputs": [],
      "source": [
        "#Find the Features from CNN's FC layer for n number of test images and we will get n x 256\n",
        "i=0\n",
        "features_test=np.zeros(shape=(y_test.shape[0],256))\n",
        "for directory_path in glob.glob(dir_val):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (32,32))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        FC_output = FC_layer_model.predict(img)\n",
        "        features_test[i]=FC_output\n",
        "        i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AzNdRW0SLhO"
      },
      "outputs": [],
      "source": [
        "#Create DataFrame with features and column name\n",
        "test_features=pd.DataFrame(data=features_test,columns=feature_col)\n",
        "feature_col = np.array(feature_col)\n",
        "\n",
        "print('Test Features Shape:', test_features.shape)\n",
        "print('Test Labels Shape:', test_label_ids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTtWk4aOSMzq"
      },
      "outputs": [],
      "source": [
        "#Feed the features of the test images to Random Forest Classifier to predict its class\n",
        "predictions = rf.predict(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0MtCbMLSNzS"
      },
      "outputs": [],
      "source": [
        "accuracy=accuracy_score(predictions , test_label_ids)\n",
        "print('Accuracy:', accuracy*100, '%.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0-1Pc0xMWoN"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "\n",
        "\n",
        "tree_estimator = rf.estimators_[0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "tree.plot_tree(tree_estimator, filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKHPxoP7eXj2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}